<!DOCTYPE html>
<html>
    <head>
        <meta http-equiv="Content-Type" content="text/html; charset=utf-8">
        <title>Sam Ribeiro</title>
        <link href="https://fonts.googleapis.com/css?family=Roboto:100,300,300i,400,500,700,900" rel="stylesheet">
        <link rel="stylesheet" type="text/css" href="mystyle.css">
    </head>
    
    <body>
        <header id="header">
            <img src="images/profile.jpg">
        </header>

        <header id="nav">
            <table>
              <tr>
                <td><a href="index.html">Home</a></td>
                <td><a href="about.html">About</a></td>
                <td><a href="research.html">Data</a></td>
                <td><a href="publications.html">Publications</a></td>
              </tr>
            </table>
        </header>

        <div id="wrapper">
        
            <main>
            <div id="content">
                    <div class="innertube">

                <p>
                    <b>UltraSuite Repository</b> </br>
                    <small>
                        UltraSuite is a repository of synchronized ultrasound and acoustic data from child speech therapy sessions.
                        Ultrasound tongue imaging (UTI) uses standard medical ultrasound to visualize the tongue surface during speech production.
                        It is increasingly being used for speech therapy, making it important to develop automatic methods to assist various 
                        time-consuming manual tasks currently performed by speech therapists.
                        The UltraSuite repository includes three data sets: one from typically developing children and two from children with speech sound disorders.
                        [<a href="https://ultrasuite.github.io/papers/ultrasuite_IS18.pdf" target="_blank">Paper</a>]
                        [<a href="https://ultrasuite.github.io" target="_blank">Documentation</a>]
                        [<a href="https://ultrasuite.github.io/download" target="_blank">Data</a>]
                    </small>
                </p>

                <p>
                    <b>Parallel Audiobook Corpus</b> </br>
                    <small>
                    The Parallel Audiobook Corpus (version 1.0) is a collection of parallel readings of audiobooks.
                    The corpus consists of approximately 121 hours of data across 4 books and 59 speakers.
                    This corpus was prepared for speech synthesis, voice conversion, or prosody modelling.
                    [<a href="https://msamribeiro.github.io/parallel-corpus" target="_blank">Documentation</a>]
                    [<a href="https://datashare.is.ed.ac.uk/handle/10283/3217" target="_blank">Data</a>]
                    </small>
                </p>

                <p>
                    <b>SIWIS Multilingual Database</b> </br>
                    <small>
                        The SIWIS database is a parallel multilingual speech database with acted emphasis.
                        It includes recordings of 36 bilingual and trilingual speakers of English, French, German and Italian with applications
                        to speech to speech translation (S2ST).
                        The database was designed for various scenarios: training CLSA systems (cross-language speaker adaptation), 
                        conveying emphasis through S2ST systems, and evaluating TTS systems.

                        [<a href="http://publications.idiap.ch/downloads/papers/2016/Goldman_IS2016.pdf" target="_blank">Paper</a>]
                        [<a href="https://www.idiap.ch/project/siwis/downloads/siwis-database" target="_blank">Data</a>]
                    </small>
                </p>

            <br>


                    </div>
                </div>
            </main>

        </div>
    </body>
</html>

